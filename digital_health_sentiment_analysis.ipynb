# **Import Libraries**
import torch
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np
## **Load and Process the Data**

  # Load the digital health dataset
df_health = pd.read_csv('patient_reviews.csv')

# Split data into train and validation
train_texts, val_texts, train_labels, val_labels = train_test_split(df_health['review'], df_health['sentiment'], test_size=0.2)

# Load the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize the patient reviews into tokens that BERT understands
train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True)

# Convert to torch tensors
train_seq = torch.tensor(train_encodings['input_ids'])
train_mask = torch.tensor(train_encodings['attention_mask'])
train_y = torch.tensor(train_labels.tolist())

val_seq = torch.tensor(val_encodings['input_ids'])
val_mask = torch.tensor(val_encodings['attention_mask'])
val_y = torch.tensor(val_labels.tolist())

# Create DataLoader
batch_size = 32

train_data = TensorDataset(train_seq, train_mask, train_y)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

val_data = TensorDataset(val_seq, val_mask, val_y)
val_sampler = SequentialSampler(val_data)
val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)
  
## **Load BERT Model For Sequence Classification**
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
model.cuda()  # Move model to GPU if available
## **Fine-Tune the Bert Model**
optimizer = AdamW(model.parameters(), lr=2e-5)

# Training loop
epochs = 3
for epoch in range(epochs):
    model.train()
    total_loss, total_accuracy = 0, 0

    # Training
    for step, batch in enumerate(train_dataloader):
        batch = [r.cuda() for r in batch]
        b_input_ids, b_input_mask, b_labels = batch
        model.zero_grad()

        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)
        loss = outputs.loss
        total_loss += loss.item()
        loss.backward()
        optimizer.step()

    avg_train_loss = total_loss / len(train_dataloader)
    print(f"Epoch {epoch + 1}/{epochs}, Training loss: {avg_train_loss}")

    # Validation
    model.eval()
    total_eval_accuracy = 0

    for batch in val_dataloader:
        batch = [t.cuda() for t in batch]
        b_input_ids, b_input_mask, b_labels = batch

        with torch.no_grad():
            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)

        logits = outputs.logits
        logits = logits.detach().cpu().numpy()
        label_ids = b_labels.to('cpu').numpy()

        total_eval_accuracy += accuracy_score(label_ids, np.argmax(logits, axis=1))

    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)
    print(f"Epoch {epoch + 1}/{epochs}, Validation Accuracy: {avg_val_accuracy}")
## **Save and Load the Model**

# Save the model
model.save_pretrained('my_digital_health_model')

# Load the model
model = BertForSequenceClassification.from_pretrained('my_digital_health_model')
          
## **Use the Model for Prediction**

# Function to predict sentiment
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    inputs = {k: v.cuda() for k, v in inputs.items()}
    with torch.no_grad():
        logits = model(**inputs).logits
    return logits.argmax(-1).item()

# Test the model
sample_reviews = [
    "The telemedicine service is convenient and efficient.",
    "I had a bad experience with the customer support team.",
    "The platform is user-friendly, and I like the health tracking features.",
]

for review in sample_reviews:
    sentiment = "Positive" if predict_sentiment(review) == 1 else "Negative"
    print(f"Review: {review}\nPredicted Sentiment: {sentiment}\n{'='*40}")
